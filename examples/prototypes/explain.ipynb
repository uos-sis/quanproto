{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype explanations\n",
    "\n",
    "This script generates the typical prototype explanations for a prediction.\n",
    "\n",
    "1) make sure to run the explanation script to generate a json file containing the nearest images in the training set for each prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import skimage as ski\n",
    "from quanproto.metrics import helpers\n",
    "\n",
    "from quanproto.utils.workspace import EXPERIMENTS_PATH, DATASET_DIR\n",
    "from quanproto.evaluation import folder_utils as eval\n",
    "from quanproto.dataloader.single_augmentation import test_dataloader, prune_dataloader\n",
    "from quanproto.explanations.config_parser import load_model\n",
    "from torch.nn.functional import max_pool2d\n",
    "from quanproto.utils.vis_helper import save_image_mask\n",
    "from quanproto.metrics.helpers import label_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_config = {\n",
    "    \"experiment_dir\": f\"{EXPERIMENTS_PATH}/ProtoPool/nico\",\n",
    "    \"dataset_dir\": DATASET_DIR,\n",
    "    \"model\": \"protopool\",\n",
    "    \"run\": \"ocean-mountain-547\",\n",
    "    \"explanation\": \"prp\",\n",
    "    \"train_phase\": \"fine_tune\",\n",
    "    \"crop\": True,\n",
    "}\n",
    "\n",
    "# test_image_idx = 970 # index of the image to explain\n",
    "test_image_idx = 205 # index of the image to explain\n",
    "# test_image_idx = 6010 # index of the image to explain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info from all runs in the experiment dir\n",
    "run_info = eval.get_run_info(experiment_config)\n",
    "run_info = run_info[experiment_config[\"run\"]]\n",
    "run_topk_info = eval.get_technique_results(\n",
    "    experiment_config)[\"topk_prototype_images\"]\n",
    "\n",
    "with open(run_topk_info[experiment_config[\"run\"]], \"r\") as f:\n",
    "    topk_info = json.load(f)\n",
    "\n",
    "# load the config file\n",
    "with open(run_info[\"config\"], \"r\") as f:\n",
    "    run_config = json.load(f)\n",
    "\n",
    "# make sure to use the datasets on your computer and not the path that was used to train the model\n",
    "run_config[\"dataset_dir\"] = experiment_config[\"dataset_dir\"]\n",
    "\n",
    "dataloader = test_dataloader(run_config,crop=experiment_config[\"crop\"])\n",
    "\n",
    "model = load_model(\n",
    "    run_config,\n",
    "    experiment_config[\"explanation\"],\n",
    "    run_info[experiment_config[\"train_phase\"]],\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_prototypes(ids, dataloader, model, topk_info):\n",
    "    \"\"\"\n",
    "    Visualize the prototypes for the given image ids.\n",
    "    \"\"\"\n",
    "    # make the ids tensor with BxN into a list \n",
    "    for img_i in range(ids.shape[0]): # all images\n",
    "        for proto_j in range(ids.shape[1]): # all prototypes\n",
    "            proto_idx = ids[img_i][proto_j]\n",
    "            prototype_info = topk_info[f\"{proto_idx}\"]\n",
    "\n",
    "            img_ids = prototype_info[\"ids\"]\n",
    "\n",
    "            img_batch = torch.zeros((len(img_ids), 3, 224, 224))\n",
    "            for proto_nearest_i, proto_nearest_id in enumerate(img_ids):\n",
    "                # get the image tensor\n",
    "                img, _ = dataloader.dataset.getitem_by_id(proto_nearest_id)\n",
    "                img_batch[proto_nearest_i] = img\n",
    "\n",
    "            img_batch = img_batch.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # make a Bx1 tensor with the prototype index\n",
    "                prototype_idx = torch.tensor([proto_idx]).cuda()\n",
    "                prototype_idx = prototype_idx.expand(\n",
    "                    img_batch.shape[0], prototype_idx.shape[0]\n",
    "                )\n",
    "                saliency_maps = model.saliency_maps(img_batch, prototype_idx)\n",
    "                saliency_masks = torch.stack(\n",
    "                    [\n",
    "                        helpers.percentile_mask(saliency_maps[b, 0])\n",
    "                        for b in range(saliency_maps.shape[0])\n",
    "                    ]\n",
    "                ).unsqueeze(1)\n",
    "                saliency_maps = saliency_maps * saliency_masks\n",
    "\n",
    "                for save_img_i in range(img_batch.shape[0]):\n",
    "                    # get the image tensor\n",
    "                    img = img_batch[save_img_i]\n",
    "                    # get the saliency maps for the image\n",
    "                    saliency_map = saliency_maps[save_img_i][0]\n",
    "\n",
    "                    # save the saliency map\n",
    "                    save_image_mask(img, saliency_map, f\"{experiment_config[\"experiment_dir\"]}/topk_explain/train_nearest_img_{save_img_i}_prototype_{proto_idx}.png\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_test_images(ids, dataloader, model):\n",
    "    \"\"\"\n",
    "    Visualize the test image for the given image ids.\n",
    "    \"\"\"\n",
    "    # 1) get the image tensor from the dataloader\n",
    "    img_batch = torch.zeros((len(ids), 3, 224, 224))\n",
    "    for i, id in enumerate(ids):\n",
    "        # get the image tensor\n",
    "        img, label = dataloader.dataset[id] \n",
    "        img_batch[i] = img\n",
    "        print(f\"Loaded image {i+1}/{len(ids)}: {id} label: {label}\")\n",
    "\n",
    "    img_batch = img_batch.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # region TopK Prototypes ---------------------------------------------------------------\n",
    "        logits, similarity_maps, _ = model.explain(img_batch)\n",
    "        if not model.multi_label:\n",
    "            if logits.dim() == 2:\n",
    "                print(f\"max logit id: {logits.argmax(dim=1)}\")\n",
    "            else:\n",
    "                print(f\"max logit id: {logits.argmax()}\")\n",
    "        else:\n",
    "            logits = label_prediction(logits, model.multi_label, 1.4552792310714722)\n",
    "            print(f\"shape: {logits.shape}\")\n",
    "            print(f\"logits: {logits}\")\n",
    "            # print how many 1s are at the same position between label and logits\n",
    "            print(f\"true pos: {((logits.to(device='cpu') == label) & (label == 1.0)).sum()}/{label.sum()}\")\n",
    "            print(f\"true neg: {((logits.to(device='cpu') == label) & (label == 0.0)).sum()}/{(label * -1 + 1).sum()}\")\n",
    "\n",
    "        similarity_scores = (\n",
    "            max_pool2d(similarity_maps, kernel_size=similarity_maps.shape[2:])\n",
    "            .squeeze(-1)\n",
    "            .squeeze(-1)\n",
    "        )\n",
    "        # get the top k similarity scores indices\n",
    "        k = 5\n",
    "        _, topk_indices = torch.topk(similarity_scores, k=k, dim=1)\n",
    "        # endregion TopK Prototypes ------------------------------------------------------------\n",
    "        saliency_maps = model.saliency_maps(img_batch, topk_indices)\n",
    "        saliency_masks = torch.stack(\n",
    "            [\n",
    "                torch.stack(\n",
    "                    [\n",
    "                        helpers.percentile_mask(saliency_maps[b, i])\n",
    "                        for i in range(k)\n",
    "                    ]\n",
    "                )\n",
    "                for b in range(saliency_maps.shape[0])\n",
    "            ]\n",
    "        )\n",
    "        saliency_maps = saliency_maps * saliency_masks\n",
    "\n",
    "        for i in range(img_batch.shape[0]):\n",
    "            # get the image tensor\n",
    "            img = img_batch[i]\n",
    "            # get the saliency maps for the image\n",
    "            saliency_map = saliency_maps[i]\n",
    "\n",
    "            for j in range(saliency_map.shape[0]):\n",
    "                # get the saliency map for the prototype\n",
    "                saliency_map_j = saliency_map[j]\n",
    "                # save the saliency map\n",
    "                save_image_mask(img, saliency_map_j, f\"{experiment_config[\"experiment_dir\"]}/topk_explain/test_img_{i}_prototype_{j}.png\")\n",
    "    return topk_indices.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_ids = vis_test_images([test_image_idx], dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prune_dataloader(run_config, crop=experiment_config[\"crop\"]) \n",
    "vis_prototypes(prototype_ids, train_data, model, topk_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
