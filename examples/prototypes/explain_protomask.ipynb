{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype explanations\n",
    "\n",
    "This script generates the typical prototype explanations for a prediction.\n",
    "\n",
    "1) make sure to run the explanation script to generate a json file containing the nearest images in the training set for each prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import skimage as ski\n",
    "from quanproto.metrics import helpers\n",
    "\n",
    "from quanproto.utils.workspace import EXPERIMENTS_PATH, DATASET_DIR\n",
    "from quanproto.evaluation import folder_utils as eval\n",
    "from quanproto.dataloader.contrastivity_segmentation import test_dataloader\n",
    "from quanproto.explanations.config_parser import load_model\n",
    "from torch.nn.functional import max_pool2d\n",
    "from quanproto.utils.vis_helper import save_image_mask\n",
    "from quanproto.utils.vis_helper import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_config = {\n",
    "    \"experiment_dir\": f\"{EXPERIMENTS_PATH}/ProtoMask/cub200\",\n",
    "    \"dataset_dir\": DATASET_DIR,\n",
    "    \"model\": \"protomask\",\n",
    "    \"run\": \"banana-sunset-583\",\n",
    "    \"explanation\": \"prp\",\n",
    "    \"train_phase\": \"fine_tune\",\n",
    "    \"crop\": True,\n",
    "}\n",
    "\n",
    "test_image_idx = 970 # index of the image to explain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info from all runs in the experiment dir\n",
    "run_info = eval.get_run_info(experiment_config)\n",
    "run_info = run_info[experiment_config[\"run\"]]\n",
    "run_topk_info = eval.get_technique_results(\n",
    "    experiment_config)[\"topk_prototype_images\"]\n",
    "\n",
    "with open(run_topk_info[experiment_config[\"run\"]], \"r\") as f:\n",
    "    topk_info = json.load(f)\n",
    "\n",
    "# load the config file\n",
    "with open(run_info[\"config\"], \"r\") as f:\n",
    "    run_config = json.load(f)\n",
    "\n",
    "# make sure to use the datasets on your computer and not the path that was used to train the model\n",
    "run_config[\"dataset_dir\"] = experiment_config[\"dataset_dir\"]\n",
    "\n",
    "dataloader = test_dataloader(run_config,crop=experiment_config[\"crop\"], fill_background_method=\"original\")\n",
    "\n",
    "model = load_model(\n",
    "    run_config,\n",
    "    experiment_config[\"explanation\"],\n",
    "    run_info[experiment_config[\"train_phase\"]],\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_prototypes(ids, dataloader, model, topk_info):\n",
    "    \"\"\"\n",
    "    Visualize the prototypes for the given image ids.\n",
    "    \"\"\"\n",
    "    # make the ids tensor with BxN into a list \n",
    "    for img_i in range(ids.shape[0]): # all images\n",
    "        for proto_j in range(ids.shape[1]): # all prototypes\n",
    "            proto_idx = ids[img_i][proto_j]\n",
    "            prototype_info = topk_info[f\"{proto_idx}\"]\n",
    "\n",
    "            img_ids = prototype_info[\"ids\"]\n",
    "\n",
    "            img_batch = torch.zeros((len(img_ids), 3, 224, 224))\n",
    "            for proto_nearest_i, proto_nearest_id in enumerate(img_ids):\n",
    "                # get the image tensor\n",
    "                img, _ = dataloader.dataset.getitem_by_id(proto_nearest_id)\n",
    "                img_batch[proto_nearest_i] = img\n",
    "\n",
    "            img_batch = img_batch.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # make a Bx1 tensor with the prototype index\n",
    "                prototype_idx = torch.tensor([proto_idx]).cuda()\n",
    "                prototype_idx = prototype_idx.expand(\n",
    "                    img_batch.shape[0], prototype_idx.shape[0]\n",
    "                )\n",
    "                saliency_maps = model.saliency_maps(img_batch, prototype_idx)\n",
    "                saliency_masks = torch.stack(\n",
    "                    [\n",
    "                        helpers.percentile_mask(saliency_maps[b, 0])\n",
    "                        for b in range(saliency_maps.shape[0])\n",
    "                    ]\n",
    "                ).unsqueeze(1)\n",
    "                saliency_maps = saliency_maps * saliency_masks\n",
    "\n",
    "                for save_img_i in range(img_batch.shape[0]):\n",
    "                    # get the image tensor\n",
    "                    img = img_batch[save_img_i]\n",
    "                    # get the saliency maps for the image\n",
    "                    saliency_map = saliency_maps[save_img_i][0]\n",
    "\n",
    "                    # save the saliency map\n",
    "                    save_image_mask(img, saliency_map, f\"{experiment_config[\"experiment_dir\"]}/topk_explain/train_nearest_img_{save_img_i}_prototype_{proto_idx}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_test_images(ids, dataloader, model):\n",
    "    \"\"\"\n",
    "    Visualize the test image for the given image ids.\n",
    "    \"\"\"\n",
    "    num_masks = dataloader.dataset.num_masks\n",
    "    # 1) get the image tensor from the dataloader\n",
    "    mask_batch = torch.zeros((len(ids), num_masks, 3, 224, 224))\n",
    "    uncropped_mask_batch = torch.zeros((len(ids), num_masks, 3, 224, 224))\n",
    "    original_bboxes_batch = torch.zeros((len(ids), num_masks, 4))\n",
    "    original_mask_size_batch = torch.zeros((len(ids), 2))\n",
    "    for i, id in enumerate(ids):\n",
    "        # get the image tensor\n",
    "        (masks, uncropped_masks, original_bboxes, original_mask_size), label = dataloader.dataset[id]\n",
    "        mask_batch[i] = masks\n",
    "        uncropped_mask_batch[i] = uncropped_masks\n",
    "        original_bboxes_batch[i] = original_bboxes\n",
    "        original_mask_size_batch[i] = original_mask_size\n",
    "\n",
    "    mask_batch = mask_batch.cuda()\n",
    "    uncropped_mask_batch = uncropped_mask_batch.cuda()\n",
    "    original_bboxes_batch = original_bboxes_batch\n",
    "    original_mask_size_batch = original_mask_size_batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # region TopK Prototypes ---------------------------------------------------------------\n",
    "        _, similarity_maps, _ = model.explain(mask_batch)\n",
    "\n",
    "        similarity_scores = (\n",
    "            max_pool2d(similarity_maps, kernel_size=similarity_maps.shape[2:])\n",
    "            .squeeze(-1)\n",
    "            .squeeze(-1)\n",
    "        )\n",
    "        # get the top k similarity scores indices\n",
    "        k = 5\n",
    "        _, topk_indices = torch.topk(similarity_scores, k=k, dim=1)\n",
    "        # endregion TopK Prototypes ---------------------------------------------------------\n",
    "        saliency_maps, mask_ids = model.saliency_maps(\n",
    "            mask_batch, uncropped_mask_batch, original_bboxes_batch, original_mask_size_batch, topk_indices\n",
    "        )\n",
    "        if model.explanation_type == \"mask\":\n",
    "            saliency_masks = saliency_maps.clone().detach()\n",
    "        if model.explanation_type == \"prp\":\n",
    "            saliency_masks = torch.stack(\n",
    "                [\n",
    "                    torch.stack(\n",
    "                        [helpers.percentile_mask(saliency_maps[b, i]) for i in range(k)]\n",
    "                    )\n",
    "                    for b in range(saliency_maps.shape[0])\n",
    "                ]\n",
    "            )\n",
    "            saliency_maps = saliency_maps * saliency_masks\n",
    "            print(f\"saliency_maps shape: {saliency_maps.shape}\")\n",
    "\n",
    "        # save the saliency maps for the test images\n",
    "        print(f\"mask_batch shape: {mask_batch.shape}\")\n",
    "        for i in range(mask_batch.shape[0]):\n",
    "            # save all masks for the image\n",
    "            for j in range(mask_batch.shape[1]):\n",
    "                # get the mask tensor\n",
    "                mask = mask_batch[i][j]\n",
    "                print(f\"mask shape: {mask.shape}\")\n",
    "                save_image(mask, f\"{experiment_config['experiment_dir']}/topk_explain/test_img_{i}_mask_{j}.png\")\n",
    "            # get the image tensor\n",
    "            img = mask_batch[i][mask_ids[i]]\n",
    "            print(f\"img shape: {img.shape}\")\n",
    "            # get the saliency maps for the image\n",
    "            saliency_map = saliency_maps[i]\n",
    "\n",
    "            for j in range(saliency_map.shape[0]):\n",
    "                # get the saliency map for the prototype\n",
    "                saliency_map_j = saliency_map[j]\n",
    "                # save the saliency map\n",
    "                save_image_mask(img, saliency_map_j, f\"{experiment_config[\"experiment_dir\"]}/topk_explain/test_img_{i}_prototype_{j}.png\")\n",
    "    return topk_indices.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_ids = vis_test_images([test_image_idx], dataloader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
